{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92546576-620c-44ff-8893-da1065ef24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import awswrangler as wr\n",
    "import redshift_connector\n",
    "\n",
    "# --- File and Table ---\n",
    "FILENAME='customer.csv'\n",
    "EXCEL_PATH = 'AWSCloud/Adventure Works on AWs/Entities used in Dashboard/DimCustomer.csv'\n",
    "TARGET_TABLE = 'dimCustomer'\n",
    "STAGING_TABLE = 'customer'\n",
    "\n",
    "# --- S3 and Redshift config ---\n",
    "S3_BUCKET = 'bucket'\n",
    "S3_PATH = f's3://{S3_BUCKET}/{FILENAME}'\n",
    "AWS_REGION = 'eu-north-1'\n",
    "IAM_ROLE = 'XXX'  # Role with S3 read access\n",
    "\n",
    "# --- Setup logging ---\n",
    "logging.basicConfig(filename='person.log',\n",
    "                    level=logging.INFO,\n",
    "                    #format='%(asctime)s %(levelname)s %(lineno)d : %(message)s')\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')\n",
    "\n",
    "# --- Redshift credentials ---\n",
    "REDSHIFT_CONFIG = {\n",
    "    'database': 'dev',\n",
    "    'user': 'admin',\n",
    "    'password': 'XXXXXX',\n",
    "    'host': 'XXXXX',\n",
    "    'port': 'XXXX' \n",
    "}\n",
    "\n",
    "\n",
    "# --- Connect to Redshift ---\n",
    "def get_redshift_connection():\n",
    "    try:\n",
    "        conn = redshift_connector.connect(**REDSHIFT_CONFIG)\n",
    "        conn.autocommit = False\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Redshift connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Load Excel & drop duplicates ---\n",
    "def load_and_clean_excel(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path,encoding=\"cp1252\")\n",
    "        logging.info(f\"Loaded Excel with {len(df)} rows.\")\n",
    "        \n",
    "        df.drop_duplicates(subset=['CustomerKey'], keep='last', inplace=True)\n",
    "        logging.info(f\"Removed duplicates, remaining rows: {len(df)}.\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Excel load/clean failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Upload DataFrame to S3 and load into Redshift using COPY ---\n",
    "def upload_to_staging(conn, df):\n",
    "    try:\n",
    "        # Upload CSV to S3 using awswrangler\n",
    "        wr.s3.to_csv(df,S3_PATH,index=False)\n",
    "        \n",
    "        logging.info(f\"CSV written to S3 at {S3_PATH}\")\n",
    "\n",
    "        # Run COPY command in Redshift\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"DELETE FROM {STAGING_TABLE}\")\n",
    "\n",
    "        copy_sql = f\"\"\"\n",
    "        COPY {STAGING_TABLE} (CustomerKey,FirstName,Gender,GeographyKey,MaritalStatus,Title)        \n",
    "        FROM '{S3_PATH}'\n",
    "        IAM_ROLE '{IAM_ROLE}'\n",
    "        REGION '{AWS_REGION}'\n",
    "        FORMAT AS CSV\n",
    "        TIMEFORMAT AS 'MM/DD/YYYY HH:MI'\n",
    "        ENCODING UTF8\n",
    "        IGNOREHEADER 1\n",
    "        EMPTYASNULL\n",
    "        BLANKSASNULL        \n",
    "        \"\"\"\n",
    "        cursor.execute(copy_sql)\n",
    "        logging.info(\"COPY from S3 to staging table completed.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed in upload_to_staging: {e}\")\n",
    "        raise                   \n",
    "           \n",
    "       \n",
    "# --- Merge logic to prevent duplicates ---\n",
    "def merge_data(conn):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        merge_sql = f\"\"\"\n",
    "        MERGE INTO {TARGET_TABLE} \n",
    "        USING {STAGING_TABLE} \n",
    "        ON {TARGET_TABLE}.CustomerKey = {STAGING_TABLE}.CustomerKey\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET\n",
    "                    \n",
    "                FirstName={STAGING_TABLE}.FirstName,\n",
    "                Gender={STAGING_TABLE}.Gender  ,\n",
    "                GeographyKey={STAGING_TABLE}.GeographyKey,\n",
    "                MaritalStatus={STAGING_TABLE}.MaritalStatus,\n",
    "                Title={STAGING_TABLE}.Title                \n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT (CustomerKey,FirstName,Gender,GeographyKey,MaritalStatus,Title)\n",
    "            VALUES ({STAGING_TABLE}.CustomerKey,{STAGING_TABLE}.FirstName ,{STAGING_TABLE}.Gender,{STAGING_TABLE}.GeographyKey,{STAGING_TABLE}.MaritalStatus,{STAGING_TABLE}.Title);\n",
    "        \"\"\"\n",
    "        cursor.execute(merge_sql)\n",
    "        logging.info(\"Merge completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Merge failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main pipeline ---\n",
    "def main():\n",
    "    try:\n",
    "        print(os.getcwd())\n",
    "        df = load_and_clean_excel(EXCEL_PATH)\n",
    "        conn = get_redshift_connection()\n",
    "        upload_to_staging(conn,df)\n",
    "        merge_data(conn)\n",
    "        conn.commit()\n",
    "        logging.info(\"Pipeline finished successfully.\")\n",
    "    except Exception as e:\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "            logging.error(\"Rolled back due to failure.\")\n",
    "        logging.error(f\"Pipeline failed: {e}\")\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
